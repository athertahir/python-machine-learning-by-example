{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "Source codes for Python Machine Learning By Example 2nd Edition (Packt Publishing)\n", 
        "Chapter 3: Mining the 20 Newsgroups Dataset with Clustering and Topic Modeling Algorithms\n", 
        "Author: Yuxi (Hayden) Liu"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n", 
        "\n", 
        "categories = [\n", 
        "    'alt.atheism',\n", 
        "    'talk.religion.misc',\n", 
        "    'comp.graphics',\n", 
        "    'sci.space',\n", 
        "]\n", 
        "\n", 
        "\n", 
        "groups = fetch_20newsgroups(subset='all', categories=categories)\n", 
        "\n", 
        "\n", 
        "\n", 
        "def is_letter_only(word):\n", 
        "    for char in word:\n", 
        "        if not char.isalpha():\n", 
        "            return False\n", 
        "    return True\n", 
        "\n", 
        "\n", 
        "\n", 
        "from nltk.corpus import names\n", 
        "all_names = set(names.words())\n", 
        "\n", 
        "\n", 
        "\n", 
        "from nltk.stem import WordNetLemmatizer\n", 
        "lemmatizer = WordNetLemmatizer()\n", 
        "\n", 
        "data_cleaned = []\n", 
        "\n", 
        "for doc in groups.data:\n", 
        "    doc = doc.lower()\n", 
        "    doc_cleaned = ' '.join(lemmatizer.lemmatize(word) for word in doc.split() if is_letter_only(word) and word not in all_names)\n", 
        "    data_cleaned.append(doc_cleaned)\n", 
        "\n", 
        "\n", 
        "from sklearn.feature_extraction.text import CountVectorizer\n", 
        "count_vector = CountVectorizer(stop_words=\"english\", max_features=None, max_df=0.5, min_df=2)\n", 
        "\n", 
        "data = count_vector.fit_transform(data_cleaned)\n", 
        "\n", 
        "\n", 
        "from sklearn.decomposition import NMF\n", 
        "\n", 
        "t = 20\n", 
        "nmf = NMF(n_components=t, random_state=42)\n", 
        "\n", 
        "nmf.fit(data)\n", 
        "\n", 
        "print(nmf.components_)\n", 
        "\n", 
        "terms = count_vector.get_feature_names()\n", 
        "\n", 
        "\n", 
        "for topic_idx, topic in enumerate(nmf.components_):\n", 
        "        print(\"Topic {}:\" .format(topic_idx))\n", 
        "        print(\" \".join([terms[i] for i in topic.argsort()[-10:]]))\n", 
        "\n", 
        "\n"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}