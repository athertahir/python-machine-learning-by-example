{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "Source codes for Python Machine Learning By Example 2nd Edition (Packt Publishing)\n", 
        "Chapter 9: Stock Price Prediction with Regression Algorithms\n", 
        "Author: Yuxi (Hayden) Liu\n", 
        "'''\n", 
        "import numpy as np\n", 
        "\n", 
        "\n", 
        "# Mean squared error calculation function given continuous targets of a data set,\n", 
        "def mse(targets):\n", 
        "    # When the set is empty\n", 
        "    if targets.size == 0:\n", 
        "        return 0\n", 
        "    return np.var(targets)\n", 
        "\n", 
        "def weighted_mse(groups):\n", 
        "    \"\"\" Calculate weighted MSE of children after a split\n", 
        "    Args:\n", 
        "        groups (list of children, and a child consists a list of targets)\n", 
        "    Returns:\n", 
        "        float, weighted impurity\n", 
        "    \"\"\"\n", 
        "    total = sum(len(group) for group in groups)\n", 
        "    weighted_sum = 0.0\n", 
        "    for group in groups:\n", 
        "        weighted_sum += len(group) / float(total) * mse(group)\n", 
        "    return weighted_sum\n", 
        "\n", 
        "\n", 
        "print('{0:.4f}'.format(mse(np.array([1, 2, 3]))))\n", 
        "print('{0:.4f}'.format(weighted_mse([np.array([1, 2, 3]), np.array([1, 2])])))\n", 
        "\n", 
        "print('type-semi: {0:.4f}'.format(weighted_mse([np.array([600, 400, 700]), np.array([700, 800])])))\n", 
        "print('bedroom-2: {0:.4f}'.format(weighted_mse([np.array([700, 400]), np.array([600, 800, 700])])))\n", 
        "print('bedroom-3: {0:.4f}'.format(weighted_mse([np.array([600, 800]), np.array([700, 400, 700])])))\n", 
        "print('bedroom-4: {0:.4f}'.format(weighted_mse([np.array([700]), np.array([600, 700, 800, 400])])))\n", 
        "\n", 
        "\n", 
        "print('bedroom-2: {0:.4f}'.format(weighted_mse([np.array([]), np.array([600, 400, 700])])))\n", 
        "print('bedroom-3: {0:.4f}'.format(weighted_mse([np.array([400]), np.array([600, 700])])))\n", 
        "print('bedroom-4: {0:.4f}'.format(weighted_mse([np.array([400, 600]), np.array([700])])))\n", 
        "\n", 
        "\n", 
        "\n", 
        "\n", 
        "def split_node(X, y, index, value):\n", 
        "    \"\"\" Split data set X, y based on a feature and a value\n", 
        "    Args:\n", 
        "        X, y (numpy.ndarray, data set)\n", 
        "        index (int, index of the feature used for splitting)\n", 
        "        value (value of the feature used for splitting)\n", 
        "    Returns:\n", 
        "        list, list: left and right child, a child is in the format of [X, y]\n", 
        "    \"\"\"\n", 
        "    x_index = X[:, index]\n", 
        "    # if this feature is numerical\n", 
        "    if type(X[0, index]) in [int, float]:\n", 
        "        mask = x_index >= value\n", 
        "    # if this feature is categorical\n", 
        "    else:\n", 
        "        mask = x_index == value\n", 
        "    # split into left and right child\n", 
        "    left = [X[~mask, :], y[~mask]]\n", 
        "    right = [X[mask, :], y[mask]]\n", 
        "    return left, right\n", 
        "\n", 
        "\n", 
        "def get_best_split(X, y):\n", 
        "    \"\"\" Obtain the best splitting point and resulting children for the data set X, y\n", 
        "    Args:\n", 
        "        X, y (numpy.ndarray, data set)\n", 
        "        criterion (gini or entropy)\n", 
        "    Returns:\n", 
        "        dict {index: index of the feature, value: feature value, children: left and right children}\n", 
        "    \"\"\"\n", 
        "    best_index, best_value, best_score, children = None, None, 1e10, None\n", 
        "    for index in range(len(X[0])):\n", 
        "        for value in np.sort(np.unique(X[:, index])):\n", 
        "            groups = split_node(X, y, index, value)\n", 
        "            impurity = weighted_mse([groups[0][1], groups[1][1]])\n", 
        "            if impurity < best_score:\n", 
        "                best_index, best_value, best_score, children = index, value, impurity, groups\n", 
        "    return {'index': best_index, 'value': best_value, 'children': children}\n", 
        "\n", 
        "\n", 
        "\n", 
        "def get_leaf(targets):\n", 
        "    # Obtain the leaf as the mean of the targets\n", 
        "    return np.mean(targets)\n", 
        "\n", 
        "\n", 
        "\n", 
        "def split(node, max_depth, min_size, depth):\n", 
        "    \"\"\" Split children of a node to construct new nodes or assign them terminals\n", 
        "    Args:\n", 
        "        node (dict, with children info)\n", 
        "        max_depth (int, maximal depth of the tree)\n", 
        "        min_size (int, minimal samples required to further split a child)\n", 
        "        depth (int, current depth of the node)\n", 
        "    \"\"\"\n", 
        "    left, right = node['children']\n", 
        "    del (node['children'])\n", 
        "    if left[1].size == 0:\n", 
        "        node['right'] = get_leaf(right[1])\n", 
        "        return\n", 
        "    if right[1].size == 0:\n", 
        "        node['left'] = get_leaf(left[1])\n", 
        "        return\n", 
        "    # Check if the current depth exceeds the maximal depth\n", 
        "    if depth >= max_depth:\n", 
        "        node['left'], node['right'] = get_leaf(left[1]), get_leaf(right[1])\n", 
        "        return\n", 
        "    # Check if the left child has enough samples\n", 
        "    if left[1].size <= min_size:\n", 
        "        node['left'] = get_leaf(left[1])\n", 
        "    else:\n", 
        "        # It has enough samples, we further split it\n", 
        "        result = get_best_split(left[0], left[1])\n", 
        "        result_left, result_right = result['children']\n", 
        "        if result_left[1].size == 0:\n", 
        "            node['left'] = get_leaf(result_right[1])\n", 
        "        elif result_right[1].size == 0:\n", 
        "            node['left'] = get_leaf(result_left[1])\n", 
        "        else:\n", 
        "            node['left'] = result\n", 
        "            split(node['left'], max_depth, min_size, depth + 1)\n", 
        "    # Check if the right child has enough samples\n", 
        "    if right[1].size <= min_size:\n", 
        "        node['right'] = get_leaf(right[1])\n", 
        "    else:\n", 
        "        # It has enough samples, we further split it\n", 
        "        result = get_best_split(right[0], right[1])\n", 
        "        result_left, result_right = result['children']\n", 
        "        if result_left[1].size == 0:\n", 
        "            node['right'] = get_leaf(result_right[1])\n", 
        "        elif result_right[1].size == 0:\n", 
        "            node['right'] = get_leaf(result_left[1])\n", 
        "        else:\n", 
        "            node['right'] = result\n", 
        "            split(node['right'], max_depth, min_size, depth + 1)\n", 
        "\n", 
        "\n", 
        "def train_tree(X_train, y_train, max_depth, min_size):\n", 
        "    \"\"\" Construction of a tree starts here\n", 
        "    Args:\n", 
        "        X_train,  y_train (list, list, training data)\n", 
        "        max_depth (int, maximal depth of the tree)\n", 
        "        min_size (int, minimal samples required to further split a child)\n", 
        "    \"\"\"\n", 
        "    root = get_best_split(X_train, y_train)\n", 
        "    split(root, max_depth, min_size, 1)\n", 
        "    return root\n", 
        "\n", 
        "\n", 
        "\n", 
        "CONDITION = {'numerical': {'yes': '>=', 'no': '<'},\n", 
        "             'categorical': {'yes': 'is', 'no': 'is not'}}\n", 
        "def visualize_tree(node, depth=0):\n", 
        "    if isinstance(node, dict):\n", 
        "        if type(node['value']) in [int, float]:\n", 
        "            condition = CONDITION['numerical']\n", 
        "        else:\n", 
        "            condition = CONDITION['categorical']\n", 
        "        print('{}|- X{} {} {}'.format(depth * '  ', node['index'] + 1, condition['no'], node['value']))\n", 
        "        if 'left' in node:\n", 
        "            visualize_tree(node['left'], depth + 1)\n", 
        "        print('{}|- X{} {} {}'.format(depth * '  ', node['index'] + 1, condition['yes'], node['value']))\n", 
        "        if 'right' in node:\n", 
        "            visualize_tree(node['right'], depth + 1)\n", 
        "    else:\n", 
        "        print('{}[{}]'.format(depth * '  ', node))\n", 
        "\n", 
        "\n", 
        "X_train = np.array([['semi', 3],\n", 
        "                    ['detached', 2],\n", 
        "                    ['detached', 3],\n", 
        "                    ['semi', 2],\n", 
        "                    ['semi', 4]], dtype=object)\n", 
        "\n", 
        "y_train = np.array([600, 700, 800, 400, 700])\n", 
        "\n", 
        "tree = train_tree(X_train, y_train, 2, 2)\n", 
        "visualize_tree(tree)\n", 
        "\n", 
        "\n", 
        "\n", 
        "# Directly use DecisionTreeRegressor from scikit-learn\n", 
        "from sklearn import datasets\n", 
        "boston = datasets.load_boston()\n", 
        "\n", 
        "num_test = 10    # the last 10 samples as testing set\n", 
        "X_train = boston.data[:-num_test, :]\n", 
        "y_train = boston.target[:-num_test]\n", 
        "X_test = boston.data[-num_test:, :]\n", 
        "y_test = boston.target[-num_test:]\n", 
        "\n", 
        "from sklearn.tree import DecisionTreeRegressor\n", 
        "regressor = DecisionTreeRegressor(max_depth=10, min_samples_split=3)\n", 
        "\n", 
        "regressor.fit(X_train, y_train)\n", 
        "predictions = regressor.predict(X_test)\n", 
        "print(predictions)\n", 
        "print(y_test)\n", 
        "\n", 
        "\n", 
        "from sklearn.ensemble import RandomForestRegressor\n", 
        "regressor = RandomForestRegressor(n_estimators=100, max_depth=10, min_samples_split=3)\n", 
        "regressor.fit(X_train, y_train)\n", 
        "predictions = regressor.predict(X_test)\n", 
        "print(predictions)\n", 
        "\n", 
        "\n", 
        "\n", 
        "\n", 
        "\n", 
        "import tensorflow as tf\n", 
        "from tensorflow.contrib.tensor_forest.python import tensor_forest\n", 
        "from tensorflow.python.ops import resources\n", 
        "\n", 
        "\n", 
        "n_iter = 20\n", 
        "n_features = int(X_train.shape[1])\n", 
        "n_trees = 10\n", 
        "max_nodes = 30000\n", 
        "\n", 
        "\n", 
        "x = tf.placeholder(tf.float32, shape=[None, n_features])\n", 
        "y = tf.placeholder(tf.float32, shape=[None])\n", 
        "\n", 
        "\n", 
        "hparams = tensor_forest.ForestHParams(num_classes=1, regression=True, num_features=n_features, num_trees=n_trees,\n", 
        "                                      max_nodes=max_nodes, split_after_samples=30).fill()\n", 
        "\n", 
        "\n", 
        "forest_graph = tensor_forest.RandomForestGraphs(hparams)\n", 
        "\n", 
        "\n", 
        "train_op = forest_graph.training_graph(x, y)\n", 
        "loss_op = forest_graph.training_loss(x, y)\n", 
        "\n", 
        "\n", 
        "infer_op, _, _ = forest_graph.inference_graph(x)\n", 
        "\n", 
        "cost = tf.losses.mean_squared_error(labels=y, predictions=infer_op[:, 0])\n", 
        "\n", 
        "\n", 
        "\n", 
        "init_vars = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer(), resources.initialize_resources(resources.shared_resources()))\n", 
        "\n", 
        "sess = tf.Session()\n", 
        "\n", 
        "sess.run(init_vars)\n", 
        "\n", 
        "\n", 
        "for i in range(1, n_iter + 1):\n", 
        "    _, c = sess.run([train_op, cost], feed_dict={x: X_train, y: y_train})\n", 
        "    print('Iteration %i, training loss: %f' % (i, c))\n", 
        "\n", 
        "\n", 
        "pred = sess.run(infer_op, feed_dict={x: X_test})[:, 0]\n", 
        "print(pred)"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}