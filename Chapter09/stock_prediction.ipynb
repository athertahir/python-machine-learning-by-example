{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "Source codes for Python Machine Learning By Example 2nd Edition (Packt Publishing)\n", 
        "Chapter 9: Stock Price Prediction with Regression Algorithms\n", 
        "Author: Yuxi (Hayden) Liu"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "import pandas as pd\n", 
        "from sklearn.model_selection import GridSearchCV\n", 
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n", 
        "from sklearn.preprocessing import StandardScaler\n", 
        "\n", 
        "\n", 
        "def generate_features(df):\n", 
        "    \"\"\"\n", 
        "    Generate features for a stock/index based on historical price and performance\n", 
        "    @param df: dataframe with columns \"Open\", \"Close\", \"High\", \"Low\", \"Volume\", \"Adjusted Close\"\n", 
        "    @return: dataframe, data set with new features\n", 
        "    \"\"\"\n", 
        "    df_new = pd.DataFrame()\n", 
        "    # 6 original features\n", 
        "    df_new['open'] = df['Open']\n", 
        "    df_new['open_1'] = df['Open'].shift(1)\n", 
        "    df_new['close_1'] = df['Close'].shift(1)\n", 
        "    df_new['high_1'] = df['High'].shift(1)\n", 
        "    df_new['low_1'] = df['Low'].shift(1)\n", 
        "    df_new['volume_1'] = df['Volume'].shift(1)\n", 
        "    # 31 generated features\n", 
        "    # average price\n", 
        "    df_new['avg_price_5'] = df['Close'].rolling(5).mean().shift(1)\n", 
        "    df_new['avg_price_30'] = df['Close'].rolling(21).mean().shift(1)\n", 
        "    df_new['avg_price_365'] = df['Close'].rolling(252).mean().shift(1)\n", 
        "    df_new['ratio_avg_price_5_30'] = df_new['avg_price_5'] / df_new['avg_price_30']\n", 
        "    df_new['ratio_avg_price_5_365'] = df_new['avg_price_5'] / df_new['avg_price_365']\n", 
        "    df_new['ratio_avg_price_30_365'] = df_new['avg_price_30'] / df_new['avg_price_365']\n", 
        "    # average volume\n", 
        "    df_new['avg_volume_5'] = df['Volume'].rolling(5).mean().shift(1)\n", 
        "    df_new['avg_volume_30'] = df['Volume'].rolling(21).mean().shift(1)\n", 
        "    df_new['avg_volume_365'] = df['Volume'].rolling(252).mean().shift(1)\n", 
        "    df_new['ratio_avg_volume_5_30'] = df_new['avg_volume_5'] / df_new['avg_volume_30']\n", 
        "    df_new['ratio_avg_volume_5_365'] = df_new['avg_volume_5'] / df_new['avg_volume_365']\n", 
        "    df_new['ratio_avg_volume_30_365'] = df_new['avg_volume_30'] / df_new['avg_volume_365']\n", 
        "    # standard deviation of prices\n", 
        "    df_new['std_price_5'] = df['Close'].rolling(5).std().shift(1)\n", 
        "    df_new['std_price_30'] = df['Close'].rolling(21).std().shift(1)\n", 
        "    df_new['std_price_365'] = df['Close'].rolling(252).std().shift(1)\n", 
        "    df_new['ratio_std_price_5_30'] = df_new['std_price_5'] / df_new['std_price_30']\n", 
        "    df_new['ratio_std_price_5_365'] = df_new['std_price_5'] / df_new['std_price_365']\n", 
        "    df_new['ratio_std_price_30_365'] = df_new['std_price_30'] / df_new['std_price_365']\n", 
        "    # standard deviation of volumes\n", 
        "    df_new['std_volume_5'] = df['Volume'].rolling(5).std().shift(1)\n", 
        "    df_new['std_volume_30'] = df['Volume'].rolling(21).std().shift(1)\n", 
        "    df_new['std_volume_365'] = df['Volume'].rolling(252).std().shift(1)\n", 
        "    df_new['ratio_std_volume_5_30'] = df_new['std_volume_5'] / df_new['std_volume_30']\n", 
        "    df_new['ratio_std_volume_5_365'] = df_new['std_volume_5'] / df_new['std_volume_365']\n", 
        "    df_new['ratio_std_volume_30_365'] = df_new['std_volume_30'] / df_new['std_volume_365']\n", 
        "    # # return\n", 
        "    df_new['return_1'] = ((df['Close'] - df['Close'].shift(1)) / df['Close'].shift(1)).shift(1)\n", 
        "    df_new['return_5'] = ((df['Close'] - df['Close'].shift(5)) / df['Close'].shift(5)).shift(1)\n", 
        "    df_new['return_30'] = ((df['Close'] - df['Close'].shift(21)) / df['Close'].shift(21)).shift(1)\n", 
        "    df_new['return_365'] = ((df['Close'] - df['Close'].shift(252)) / df['Close'].shift(252)).shift(1)\n", 
        "    df_new['moving_avg_5'] = df_new['return_1'].rolling(5).mean().shift(1)\n", 
        "    df_new['moving_avg_30'] = df_new['return_1'].rolling(21).mean().shift(1)\n", 
        "    df_new['moving_avg_365'] = df_new['return_1'].rolling(252).mean().shift(1)\n", 
        "    # the target\n", 
        "    df_new['close'] = df['Close']\n", 
        "    df_new = df_new.dropna(axis=0)\n", 
        "    return df_new\n", 
        "\n", 
        "\n", 
        "data_raw = pd.read_csv('19880101_20161231.csv', index_col='Date')\n", 
        "data = generate_features(data_raw)\n", 
        "\n", 
        "start_train = '1988-01-01'\n", 
        "end_train = '2015-12-31'\n", 
        "\n", 
        "start_test = '2016-01-01'\n", 
        "end_test = '2016-12-31'\n", 
        "\n", 
        "data_train = data.ix[start_train:end_train]\n", 
        "X_train = data_train.drop('close', axis=1).values\n", 
        "y_train = data_train['close'].values\n", 
        "\n", 
        "print(X_train.shape)\n", 
        "print(y_train.shape)\n", 
        "\n", 
        "data_test = data.ix[start_test:end_test]\n", 
        "X_test = data_test.drop('close', axis=1).values\n", 
        "y_test = data_test['close'].values\n", 
        "\n", 
        "print(X_test.shape)\n", 
        "\n", 
        "\n", 
        "# First experiment with linear regression\n", 
        "\n", 
        "scaler = StandardScaler()\n", 
        "\n", 
        "X_scaled_train = scaler.fit_transform(X_train)\n", 
        "X_scaled_test = scaler.transform(X_test)\n", 
        "\n", 
        "param_grid = {\n", 
        "    \"alpha\": [1e-5, 3e-5, 1e-4],\n", 
        "    \"eta0\": [0.01, 0.03, 0.1],\n", 
        "}\n", 
        "\n", 
        "\n", 
        "from sklearn.linear_model import SGDRegressor\n", 
        "lr = SGDRegressor(penalty='l2')\n", 
        "grid_search = GridSearchCV(lr, param_grid, cv=5, scoring='r2')\n", 
        "grid_search.fit(X_scaled_train, y_train)\n", 
        "\n", 
        "print(grid_search.best_params_)\n", 
        "\n", 
        "lr_best = grid_search.best_estimator_\n", 
        "\n", 
        "predictions_lr = lr_best.predict(X_scaled_test)\n", 
        "\n", 
        "print('MSE: {0:.3f}'.format(mean_squared_error(y_test, predictions_lr)))\n", 
        "print('MAE: {0:.3f}'.format(mean_absolute_error(y_test, predictions_lr)))\n", 
        "print('R^2: {0:.3f}'.format(r2_score(y_test, predictions_lr)))\n", 
        "\n", 
        "\n", 
        "# Experiment with random forest\n", 
        "\n", 
        "param_grid = {\n", 
        "    'max_depth': [50, 70, 80],\n", 
        "    'min_samples_split': [5, 10],\n", 
        "    'max_features': ['auto', 'sqrt'],\n", 
        "    'min_samples_leaf': [3, 5]\n", 
        "\n", 
        "}\n", 
        "\n", 
        "\n", 
        "from sklearn.ensemble import RandomForestRegressor\n", 
        "\n", 
        "rf = RandomForestRegressor(n_estimators=100, n_jobs=-1)\n", 
        "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='r2', n_jobs=-1)\n", 
        "grid_search.fit(X_train, y_train)\n", 
        "\n", 
        "print(grid_search.best_params_)\n", 
        "rf_best = grid_search.best_estimator_\n", 
        "\n", 
        "predictions_rf = rf_best.predict(X_test)\n", 
        "print('MSE: {0:.3f}'.format(mean_squared_error(y_test, predictions_rf)))\n", 
        "print('MAE: {0:.3f}'.format(mean_absolute_error(y_test, predictions_rf)))\n", 
        "print('R^2: {0:.3f}'.format(r2_score(y_test, predictions_rf)))\n", 
        "\n", 
        "\n", 
        "# Experiment with SVR\n", 
        "\n", 
        "param_grid = [\n", 
        "    {'kernel': ['linear'], 'C': [100, 300, 500], 'epsilon': [0.00003, 0.0001]},\n", 
        "    {'kernel': ['rbf'], 'gamma': [1e-3, 1e-4], 'C': [10, 100, 1000], 'epsilon': [0.00003, 0.0001]}\n", 
        "]\n", 
        "\n", 
        "\n", 
        "from sklearn.svm import SVR\n", 
        "\n", 
        "svr = SVR()\n", 
        "grid_search = GridSearchCV(svr, param_grid, cv=2, scoring='r2')\n", 
        "grid_search.fit(X_scaled_train, y_train)\n", 
        "\n", 
        "print(grid_search.best_params_)\n", 
        "\n", 
        "svr_best = grid_search.best_estimator_\n", 
        "\n", 
        "predictions_svr = svr_best.predict(X_scaled_test)\n", 
        "\n", 
        "print('MSE: {0:.3f}'.format(mean_squared_error(y_test, predictions_svr)))\n", 
        "print('MAE: {0:.3f}'.format(mean_absolute_error(y_test, predictions_svr)))\n", 
        "print('R^2: {0:.3f}'.format(r2_score(y_test, predictions_svr)))\n", 
        "\n", 
        "\n", 
        "# Experiment with neural network\n", 
        "\n", 
        "param_grid = {\n", 
        "    'hidden_layer_sizes': [(50, 10), (30, 30)],\n", 
        "    'activation': ['logistic', 'tanh', 'relu'],\n", 
        "    'solver': ['sgd', 'adam'],\n", 
        "    'learning_rate_init': [0.0001, 0.0003, 0.001, 0.01],\n", 
        "    'alpha': [0.00003, 0.0001, 0.0003],\n", 
        "    'batch_size': [30, 50]\n", 
        "}\n", 
        "\n", 
        "\n", 
        "from sklearn.neural_network import MLPRegressor\n", 
        "\n", 
        "nn = MLPRegressor(random_state=42, max_iter=2000)\n", 
        "grid_search = GridSearchCV(nn, param_grid, cv=2, scoring='r2', n_jobs=-1)\n", 
        "grid_search.fit(X_scaled_train, y_train)\n", 
        "\n", 
        "\n", 
        "print(grid_search.best_params_)\n", 
        "\n", 
        "nn_best = grid_search.best_estimator_\n", 
        "\n", 
        "predictions_nn = nn_best.predict(X_scaled_test)\n", 
        "\n", 
        "print('MSE: {0:.3f}'.format(mean_squared_error(y_test, predictions_nn)))\n", 
        "print('MAE: {0:.3f}'.format(mean_absolute_error(y_test, predictions_nn)))\n", 
        "print('R^2: {0:.3f}'.format(r2_score(y_test, predictions_nn)))\n", 
        "\n", 
        "\n", 
        "\n"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}