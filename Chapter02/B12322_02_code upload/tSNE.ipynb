{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "Source codes for Python Machine Learning By Example 2nd Edition (Packt Publishing)\n", 
        "Chapter 2: Exploring the 20 Newsgroups Dataset with Text Analysis Techniques\n", 
        "Author: Yuxi (Hayden) Liu\n", 
        "'''\n", 
        "\n", 
        "from sklearn.datasets import fetch_20newsgroups\n", 
        "from sklearn.feature_extraction.text import CountVectorizer\n", 
        "\n", 
        "\n", 
        "categories_3 = ['talk.religion.misc', 'comp.graphics', 'sci.space']\n", 
        "\n", 
        "groups_3 = fetch_20newsgroups(categories=categories_3)\n", 
        "\n", 
        "\n", 
        "\n", 
        "def is_letter_only(word):\n", 
        "    for char in word:\n", 
        "        if not char.isalpha():\n", 
        "            return False\n", 
        "    return True\n", 
        "\n", 
        "\n", 
        "\n", 
        "from nltk.corpus import names\n", 
        "all_names = set(names.words())\n", 
        "\n", 
        "\n", 
        "count_vector_sw = CountVectorizer(stop_words=\"english\", max_features=500)\n", 
        "\n", 
        "\n", 
        "from nltk.stem import WordNetLemmatizer\n", 
        "lemmatizer = WordNetLemmatizer()\n", 
        "\n", 
        "data_cleaned = []\n", 
        "\n", 
        "for doc in groups_3.data:\n", 
        "    doc = doc.lower()\n", 
        "    doc_cleaned = ' '.join(lemmatizer.lemmatize(word) for word in doc.split() if is_letter_only(word) and word not in all_names)\n", 
        "    data_cleaned.append(doc_cleaned)\n", 
        "\n", 
        "\n", 
        "data_cleaned_count_3 = count_vector_sw.fit_transform(data_cleaned)\n", 
        "\n", 
        "\n", 
        "\n", 
        "\n", 
        "from sklearn.manifold import TSNE\n", 
        "\n", 
        "\n", 
        "tsne_model = TSNE(n_components=2,  perplexity=40, random_state=42, learning_rate=500)\n", 
        "\n", 
        "\n", 
        "data_tsne = tsne_model.fit_transform(data_cleaned_count_3.toarray())\n", 
        "\n", 
        "\n", 
        "import matplotlib.pyplot as plt\n", 
        "plt.scatter(data_tsne[:, 0], data_tsne[:, 1], c=groups_3.target)\n", 
        "\n", 
        "plt.show()\n", 
        "\n", 
        "\n", 
        "\n", 
        "\n", 
        "\n", 
        "\n", 
        "categories_5 = ['comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware',\n", 
        "                'comp.windows.x']\n", 
        "groups_5 = fetch_20newsgroups(categories=categories_5)\n", 
        "\n", 
        "count_vector_sw = CountVectorizer(stop_words=\"english\", max_features=500)\n", 
        "\n", 
        "data_cleaned = []\n", 
        "\n", 
        "for doc in groups_5.data:\n", 
        "    doc = doc.lower()\n", 
        "    doc_cleaned = ' '.join(lemmatizer.lemmatize(word) for word in doc.split() if is_letter_only(word) and word not in all_names)\n", 
        "    data_cleaned.append(doc_cleaned)\n", 
        "\n", 
        "data_cleaned_count_5 = count_vector_sw.fit_transform(data_cleaned)\n", 
        "\n", 
        "data_tsne = tsne_model.fit_transform(data_cleaned_count_5.toarray())\n", 
        "\n", 
        "plt.scatter(data_tsne[:, 0], data_tsne[:, 1], c=groups_5.target)\n", 
        "\n", 
        "plt.show()"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}