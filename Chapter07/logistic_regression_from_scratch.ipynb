{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "Source codes for Python Machine Learning By Example 2nd Edition (Packt Publishing)\n", 
        "Chapter 7: Predicting Online Ads Click-through with Logistic Regression\n", 
        "Author: Yuxi (Hayden) Liu"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "import numpy as np\n", 
        "\n", 
        "def sigmoid(input):\n", 
        "    return 1.0 / (1 + np.exp(-input))\n", 
        "\n", 
        "\n", 
        "\n", 
        "# Gradient descent based logistic regression from scratch\n", 
        "def compute_prediction(X, weights):\n", 
        "    \"\"\" Compute the prediction y_hat based on current weights\n", 
        "    Args:\n", 
        "        X (numpy.ndarray)\n", 
        "        weights (numpy.ndarray)\n", 
        "    Returns:\n", 
        "        numpy.ndarray, y_hat of X under weights\n", 
        "    \"\"\"\n", 
        "    z = np.dot(X, weights)\n", 
        "    predictions = sigmoid(z)\n", 
        "    return predictions\n", 
        "\n", 
        "def update_weights_gd(X_train, y_train, weights, learning_rate):\n", 
        "    \"\"\" Update weights by one step\n", 
        "    Args:\n", 
        "        X_train, y_train (numpy.ndarray, training data set)\n", 
        "        weights (numpy.ndarray)\n", 
        "        learning_rate (float)\n", 
        "    Returns:\n", 
        "        numpy.ndarray, updated weights\n", 
        "    \"\"\"\n", 
        "    predictions = compute_prediction(X_train, weights)\n", 
        "    weights_delta = np.dot(X_train.T, y_train - predictions)\n", 
        "    m = y_train.shape[0]\n", 
        "    weights += learning_rate / float(m) * weights_delta\n", 
        "    return weights\n", 
        "\n", 
        "def compute_cost(X, y, weights):\n", 
        "    \"\"\" Compute the cost J(w)\n", 
        "    Args:\n", 
        "        X, y (numpy.ndarray, data set)\n", 
        "        weights (numpy.ndarray)\n", 
        "    Returns:\n", 
        "        float\n", 
        "    \"\"\"\n", 
        "    predictions = compute_prediction(X, weights)\n", 
        "    cost = np.mean(-y * np.log(predictions) - (1 - y) * np.log(1 - predictions))\n", 
        "    return cost\n", 
        "\n", 
        "def train_logistic_regression(X_train, y_train, max_iter, learning_rate, fit_intercept=False):\n", 
        "    \"\"\" Train a logistic regression model\n", 
        "    Args:\n", 
        "        X_train, y_train (numpy.ndarray, training data set)\n", 
        "        max_iter (int, number of iterations)\n", 
        "        learning_rate (float)\n", 
        "        fit_intercept (bool, with an intercept w0 or not)\n", 
        "    Returns:\n", 
        "        numpy.ndarray, learned weights\n", 
        "    \"\"\"\n", 
        "    if fit_intercept:\n", 
        "        intercept = np.ones((X_train.shape[0], 1))\n", 
        "        X_train = np.hstack((intercept, X_train))\n", 
        "    weights = np.zeros(X_train.shape[1])\n", 
        "    for iteration in range(max_iter):\n", 
        "        weights = update_weights_gd(X_train, y_train, weights, learning_rate)\n", 
        "        # Check the cost for every 100 (for example) iterations\n", 
        "        if iteration % 100 == 0:\n", 
        "            print(compute_cost(X_train, y_train, weights))\n", 
        "    return weights\n", 
        "\n", 
        "def predict(X, weights):\n", 
        "    if X.shape[1] == weights.shape[0] - 1:\n", 
        "        intercept = np.ones((X.shape[0], 1))\n", 
        "        X = np.hstack((intercept, X))\n", 
        "    return compute_prediction(X, weights)\n", 
        "\n", 
        "\n", 
        "# A example\n", 
        "X_train = np.array([[6, 7],\n", 
        "                    [2, 4],\n", 
        "                    [3, 6],\n", 
        "                    [4, 7],\n", 
        "                    [1, 6],\n", 
        "                    [5, 2],\n", 
        "                    [2, 0],\n", 
        "                    [6, 3],\n", 
        "                    [4, 1],\n", 
        "                    [7, 2]])\n", 
        "\n", 
        "y_train = np.array([0,\n", 
        "                    0,\n", 
        "                    0,\n", 
        "                    0,\n", 
        "                    0,\n", 
        "                    1,\n", 
        "                    1,\n", 
        "                    1,\n", 
        "                    1,\n", 
        "                    1])\n", 
        "\n", 
        "weights = train_logistic_regression(X_train, y_train, max_iter=1000, learning_rate=0.1, fit_intercept=True)\n", 
        "\n", 
        "X_test = np.array([[6, 1],\n", 
        "                   [1, 3],\n", 
        "                   [3, 1],\n", 
        "                   [4, 5]])\n", 
        "\n", 
        "predictions = predict(X_test, weights)\n", 
        "\n", 
        "import matplotlib.pyplot as plt\n", 
        "plt.scatter(X_train[:,0], X_train[:,1], c=['b']*5+['k']*5, marker='o')\n", 
        "colours = ['k' if prediction >= 0.5 else 'b' for prediction in predictions]\n", 
        "plt.scatter(X_test[:,0], X_test[:,1], marker='*', c=colours)\n", 
        "plt.xlabel('x1')\n", 
        "plt.ylabel('x2')\n", 
        "plt.show()\n", 
        "\n", 
        "\n", 
        "\n", 
        "\n", 
        "import pandas as pd\n", 
        "n_rows = 300000\n", 
        "df = pd.read_csv(\"train\", nrows=n_rows)\n", 
        "\n", 
        "X = df.drop(['click', 'id', 'hour', 'device_id', 'device_ip'], axis=1).values\n", 
        "Y = df['click'].values\n", 
        "\n", 
        "n_train = 100000\n", 
        "X_train = X[:n_train]\n", 
        "Y_train = Y[:n_train]\n", 
        "X_test = X[n_train:]\n", 
        "Y_test = Y[n_train:]\n", 
        "\n", 
        "from sklearn.preprocessing import OneHotEncoder\n", 
        "enc = OneHotEncoder(handle_unknown='ignore')\n", 
        "X_train_enc = enc.fit_transform(X_train)\n", 
        "\n", 
        "X_test_enc = enc.transform(X_test)\n", 
        "\n", 
        "\n", 
        "import timeit\n", 
        "start_time = timeit.default_timer()\n", 
        "weights = train_logistic_regression(X_train_enc.toarray(), Y_train, max_iter=10000, learning_rate=0.01, fit_intercept=True)\n", 
        "print(\"--- %0.3fs seconds ---\" % (timeit.default_timer() - start_time))\n", 
        "\n", 
        "\n", 
        "pred = predict(X_test_enc.toarray(), weights)\n", 
        "from sklearn.metrics import roc_auc_score\n", 
        "print('Training samples: {0}, AUC on testing set: {1:.3f}'.format(n_train, roc_auc_score(Y_test, pred)))\n", 
        "\n", 
        "\n", 
        "\n", 
        "\n", 
        "\n", 
        "def update_weights_sgd(X_train, y_train, weights, learning_rate):\n", 
        "    \"\"\" One weight update iteration: moving weights by one step based on each individual sample\n", 
        "    Args:\n", 
        "        X_train, y_train (numpy.ndarray, training data set)\n", 
        "        weights (numpy.ndarray)\n", 
        "        learning_rate (float)\n", 
        "    Returns:\n", 
        "        numpy.ndarray, updated weights\n", 
        "    \"\"\"\n", 
        "    for X_each, y_each in zip(X_train, y_train):\n", 
        "        prediction = compute_prediction(X_each, weights)\n", 
        "        weights_delta = X_each.T * (y_each - prediction)\n", 
        "        weights += learning_rate * weights_delta\n", 
        "    return weights\n", 
        "\n", 
        "def train_logistic_regression_sgd(X_train, y_train, max_iter, learning_rate, fit_intercept=False):\n", 
        "    \"\"\" Train a logistic regression model via SGD\n", 
        "    Args:\n", 
        "        X_train, y_train (numpy.ndarray, training data set)\n", 
        "        max_iter (int, number of iterations)\n", 
        "        learning_rate (float)\n", 
        "        fit_intercept (bool, with an intercept w0 or not)\n", 
        "    Returns:\n", 
        "        numpy.ndarray, learned weights\n", 
        "    \"\"\"\n", 
        "    if fit_intercept:\n", 
        "        intercept = np.ones((X_train.shape[0], 1))\n", 
        "        X_train = np.hstack((intercept, X_train))\n", 
        "    weights = np.zeros(X_train.shape[1])\n", 
        "    for iteration in range(max_iter):\n", 
        "        weights = update_weights_sgd(X_train, y_train, weights, learning_rate)\n", 
        "        # Check the cost for every 2 (for example) iterations\n", 
        "        if iteration % 2 == 0:\n", 
        "            print(compute_cost(X_train, y_train, weights))\n", 
        "    return weights\n", 
        "\n", 
        "\n", 
        "# Train the SGD model based on 100000 samples\n", 
        "start_time = timeit.default_timer()\n", 
        "weights = train_logistic_regression_sgd(X_train_enc.toarray(), Y_train, max_iter=10, learning_rate=0.01, fit_intercept=True)\n", 
        "print(\"--- %0.3fs seconds ---\" % (timeit.default_timer() - start_time))\n", 
        "pred = predict(X_test_enc.toarray(), weights)\n", 
        "print('Training samples: {0}, AUC on testing set: {1:.3f}'.format(n_train, roc_auc_score(Y_test, pred)))\n", 
        "\n"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}