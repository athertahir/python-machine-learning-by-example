{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "Source codes for Python Machine Learning By Example 2nd Edition (Packt Publishing)\n", 
        "Chapter 8: Scaling Up Learning On Massive Click Logs\n", 
        "Author: Yuxi (Hayden) Liu"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }, 
    {
      "source": [
        "from pyspark.sql import SparkSession\n", 
        "\n", 
        "\n", 
        "spark = SparkSession\\\n", 
        "    .builder\\\n", 
        "    .appName(\"CTR\")\\\n", 
        "    .getOrCreate()\n", 
        "\n", 
        "\n", 
        "\n", 
        "\n", 
        "\n", 
        "from pyspark.sql.types import StructField, StringType, StructType, IntegerType\n", 
        "\n", 
        "schema = StructType([\n", 
        "    StructField(\"id\", StringType(), True),\n", 
        "    StructField(\"click\", IntegerType(), True),\n", 
        "    StructField(\"hour\", IntegerType(), True),\n", 
        "    StructField(\"C1\", StringType(), True),\n", 
        "    StructField(\"banner_pos\", StringType(), True),\n", 
        "    StructField(\"site_id\", StringType(), True),\n", 
        "    StructField(\"site_domain\", StringType(), True),\n", 
        "    StructField(\"site_category\", StringType(), True),\n", 
        "    StructField(\"app_id\", StringType(), True),\n", 
        "    StructField(\"app_domain\", StringType(), True),\n", 
        "    StructField(\"app_category\", StringType(), True),\n", 
        "    StructField(\"device_id\", StringType(), True),\n", 
        "    StructField(\"device_ip\", StringType(), True),\n", 
        "    StructField(\"device_model\", StringType(), True),\n", 
        "    StructField(\"device_type\", StringType(), True),\n", 
        "    StructField(\"device_conn_type\", StringType(), True),\n", 
        "    StructField(\"C14\", StringType(), True),\n", 
        "    StructField(\"C15\", StringType(), True),\n", 
        "    StructField(\"C16\", StringType(), True),\n", 
        "    StructField(\"C17\", StringType(), True),\n", 
        "    StructField(\"C18\", StringType(), True),\n", 
        "    StructField(\"C19\", StringType(), True),\n", 
        "    StructField(\"C20\", StringType(), True),\n", 
        "    StructField(\"C21\", StringType(), True),\n", 
        "])\n", 
        "\n", 
        "\n", 
        "\n", 
        "df = spark.read.csv(\"file:///Users/hayden/dev/project/my_python2_book/ch7/train\", schema=schema, header=True)\n", 
        "\n", 
        "\n", 
        "df = df.drop('id').drop('hour').drop('device_id').drop('device_ip')\n", 
        "\n", 
        "df = df.withColumnRenamed(\"click\", \"label\")\n", 
        "\n", 
        "\n", 
        "df_train, df_test = df.randomSplit([0.7, 0.3], 42)\n", 
        "\n", 
        "df_train.cache()\n", 
        "\n", 
        "df_test.cache()\n", 
        "\n", 
        "\n", 
        "\n", 
        "categorical = df_train.columns\n", 
        "categorical.remove('label')\n", 
        "print(categorical)\n", 
        "\n", 
        "\n", 
        "\n", 
        "from pyspark.ml.feature import FeatureHasher\n", 
        "hasher = FeatureHasher(numFeatures=10000, inputCols=categorical,\n", 
        "                       outputCol=\"features\")\n", 
        "\n", 
        "hasher.transform(df_train).select(\"features\").show()\n", 
        "\n", 
        "from pyspark.ml.classification import LogisticRegression\n", 
        "\n", 
        "classifier = LogisticRegression(maxIter=20, regParam=0.000, elasticNetParam=0.000)\n", 
        "\n", 
        "stages = [hasher, classifier]\n", 
        "\n", 
        "from pyspark.ml import Pipeline\n", 
        "\n", 
        "pipeline = Pipeline(stages=stages)\n", 
        "\n", 
        "\n", 
        "model = pipeline.fit(df_train)\n", 
        "\n", 
        "predictions = model.transform(df_test)\n", 
        "\n", 
        "\n", 
        "predictions.cache()\n", 
        "\n", 
        "\n", 
        "\n", 
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n", 
        "\n", 
        "ev = BinaryClassificationEvaluator(rawPredictionCol = \"rawPrediction\", metricName = \"areaUnderROC\")\n", 
        "print(ev.evaluate(predictions))\n", 
        "\n", 
        "\n", 
        "spark.stop()\n"
      ], 
      "cell_type": "code", 
      "execution_count": null, 
      "outputs": [], 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}