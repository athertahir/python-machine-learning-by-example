{
  "nbformat_minor": 1, 
  "nbformat": 4, 
  "cells": [
    {
      "source": [
        "Source codes for Python Machine Learning By Example 2nd Edition (Packt Publishing)\n", 
        "Chapter 8: Scaling Up Learning On Massive Click Logs\n", 
        "Author: Yuxi (Hayden) Liu\n", 
        "'''\n", 
        "\n", 
        "from pyspark.sql import SparkSession\n", 
        "\n", 
        "\n", 
        "spark = SparkSession\\\n", 
        "    .builder\\\n", 
        "    .appName(\"CTR\")\\\n", 
        "    .getOrCreate()\n", 
        "\n", 
        "\n", 
        "\n", 
        "from pyspark.sql.types import StructField, StringType, StructType, IntegerType\n", 
        "\n", 
        "schema = StructType([\n", 
        "    StructField(\"id\", StringType(), True),\n", 
        "    StructField(\"click\", IntegerType(), True),\n", 
        "    StructField(\"hour\", IntegerType(), True),\n", 
        "    StructField(\"C1\", StringType(), True),\n", 
        "    StructField(\"banner_pos\", StringType(), True),\n", 
        "    StructField(\"site_id\", StringType(), True),\n", 
        "    StructField(\"site_domain\", StringType(), True),\n", 
        "    StructField(\"site_category\", StringType(), True),\n", 
        "    StructField(\"app_id\", StringType(), True),\n", 
        "    StructField(\"app_domain\", StringType(), True),\n", 
        "    StructField(\"app_category\", StringType(), True),\n", 
        "    StructField(\"device_id\", StringType(), True),\n", 
        "    StructField(\"device_ip\", StringType(), True),\n", 
        "    StructField(\"device_model\", StringType(), True),\n", 
        "    StructField(\"device_type\", StringType(), True),\n", 
        "    StructField(\"device_conn_type\", StringType(), True),\n", 
        "    StructField(\"C14\", StringType(), True),\n", 
        "    StructField(\"C15\", StringType(), True),\n", 
        "    StructField(\"C16\", StringType(), True),\n", 
        "    StructField(\"C17\", StringType(), True),\n", 
        "    StructField(\"C18\", StringType(), True),\n", 
        "    StructField(\"C19\", StringType(), True),\n", 
        "    StructField(\"C20\", StringType(), True),\n", 
        "    StructField(\"C21\", StringType(), True),\n", 
        "])\n", 
        "\n", 
        "\n", 
        "\n", 
        "df = spark.read.csv(\"file:///Users/hayden/dev/project/my_python2_book/ch7/train\", schema=schema, header=True)\n", 
        "\n", 
        "\n", 
        "df.printSchema()\n", 
        "\n", 
        "df.count()\n", 
        "\n", 
        "df = df.drop('id').drop('hour').drop('device_id').drop('device_ip')\n", 
        "\n", 
        "df = df.withColumnRenamed(\"click\", \"label\")\n", 
        "\n", 
        "df.columns\n", 
        "\n", 
        "\n", 
        "df_train, df_test = df.randomSplit([0.7, 0.3], 42)\n", 
        "\n", 
        "df_train.cache()\n", 
        "df_train.count()\n", 
        "\n", 
        "df_test.cache()\n", 
        "df_test.count()\n", 
        "\n", 
        "\n", 
        "\n", 
        "categorical = df_train.columns\n", 
        "categorical.remove('label')\n", 
        "print(categorical)\n", 
        "\n", 
        "\n", 
        "\n", 
        "\n", 
        "\n", 
        "from pyspark.ml.feature import StringIndexer, VectorAssembler, OneHotEncoderEstimator\n", 
        "\n", 
        "\n", 
        "\n", 
        "\n", 
        "indexers = [\n", 
        "    StringIndexer(inputCol=c, outputCol=\"{0}_indexed\".format(c)).setHandleInvalid(\"keep\")\n", 
        "    for c in categorical\n", 
        "]\n", 
        "\n", 
        "encoder = OneHotEncoderEstimator(\n", 
        "    inputCols=[indexer.getOutputCol() for indexer in indexers],\n", 
        "    outputCols=[\n", 
        "        \"{0}_encoded\".format(indexer.getOutputCol()) for indexer in indexers]\n", 
        ")\n", 
        "\n", 
        "assembler = VectorAssembler(\n", 
        "    inputCols=encoder.getOutputCols(),\n", 
        "    outputCol=\"features\"\n", 
        ")\n", 
        "\n", 
        "stages = indexers + [encoder, assembler]\n", 
        "\n", 
        "from pyspark.ml import Pipeline\n", 
        "\n", 
        "\n", 
        "pipeline = Pipeline(stages=stages)\n", 
        "\n", 
        "\n", 
        "one_hot_encoder = pipeline.fit(df_train)\n", 
        "\n", 
        "\n", 
        "df_train_encoded = one_hot_encoder.transform(df_train)\n", 
        "\n", 
        "\n", 
        "df_train_encoded.show()\n", 
        "\n", 
        "df_train_encoded = df_train_encoded.select([\"label\", \"features\"])\n", 
        "\n", 
        "df_train_encoded.show()\n", 
        "\n", 
        "df_train_encoded.cache()\n", 
        "\n", 
        "df_train.unpersist()\n", 
        "\n", 
        "\n", 
        "\n", 
        "df_test_encoded = one_hot_encoder.transform(df_test)\n", 
        "\n", 
        "\n", 
        "\n", 
        "df_test_encoded = df_test_encoded.select([\"label\", \"features\"])\n", 
        "\n", 
        "df_test_encoded.show()\n", 
        "\n", 
        "df_test_encoded.cache()\n", 
        "\n", 
        "df_test.unpersist()\n", 
        "\n", 
        "\n", 
        "\n", 
        "from pyspark.ml.classification import LogisticRegression\n", 
        "\n", 
        "classifier = LogisticRegression(maxIter=20, regParam=0.000, elasticNetParam=0.000)\n", 
        "\n", 
        "lr_model = classifier.fit(df_train_encoded)\n", 
        "\n", 
        "\n", 
        "df_train_encoded.unpersist()\n", 
        "\n", 
        "predictions = lr_model.transform(df_test_encoded)\n", 
        "\n", 
        "df_test_encoded.unpersist()\n", 
        "\n", 
        "predictions.cache()\n", 
        "\n", 
        "predictions.show()\n", 
        "\n", 
        "\n", 
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n", 
        "\n", 
        "ev = BinaryClassificationEvaluator(rawPredictionCol = \"rawPrediction\", metricName = \"areaUnderROC\")\n", 
        "print(ev.evaluate(predictions))\n", 
        "\n", 
        "\n", 
        "spark.stop()"
      ], 
      "cell_type": "markdown", 
      "metadata": {}
    }
  ], 
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3", 
      "name": "python3", 
      "language": "python"
    }, 
    "language_info": {
      "mimetype": "text/x-python", 
      "nbconvert_exporter": "python", 
      "name": "python", 
      "file_extension": ".py", 
      "version": "3.6.1", 
      "pygments_lexer": "ipython3", 
      "codemirror_mode": {
        "version": 3, 
        "name": "ipython"
      }
    }, 
    "anaconda-cloud": {}
  }
}